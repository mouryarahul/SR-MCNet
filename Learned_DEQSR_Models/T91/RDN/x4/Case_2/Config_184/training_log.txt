Parameters:
 Namespace(case_num=2, config_num=184, interp_scale=4, interp_method='TORCH', fixed_dnn='RDN', rdn_num_features=64, rdn_growth_rate=64, rdn_num_blocks=16, rdn_num_layers=8, rdn_weight_file='../Learned_RDN_Models/', alpha=5.0, epsilon=1.0, rho=0.1, tol=1e-05, maxiter_forward=200, miniter_forward=5, maxiter_backward=100, miniter_backward=5, beta=0.9, jac_regul=False, jac_loss_weight=1.0, jac_loss_freq=0.35, jac_incremental=3500, spectral_radius_mode=False, dncnn_frozen=False, dncnn_num_layers=6, dncnn_lip=0.9, dncnn_bias=False, dncnn_bn=False, dncnn_skip=False, dncnn_weight_file='../Learned_DNCNN_Models/T91/RealSN_DnCNN/Layers_6/BN_False/sigma_0.01250_0.02500/best.pth', dncnn_lr=0.0001, sigmaL=0.0625, sigmaH=0.125, optimizer='adam', lr=0.0001, alpha_lr=0.001, decrease_lr=True, lr_step=60, lr_gamma=0.1, clip_grad=False, clip_norm=0.01, batch_size=512, num_epochs=80, num_workers=4, datasets_dir='../Data/', train_data='T91', eval_data='Set5', last_checkpoint='', best_weight_file='', output_dir='../Learned_DEQSR_Models', seed=123, use_gpu=True, verbose=True, verbose2=True)
Epoch No	LR            	Loss          	Val_Loss      	DF            	PSNR      	SSIM      	Beta      
       0	1.00000000e-03	1.30379787e-03	6.93914568e-04	1.06481697e-01	32.33274865	0.90687684	4.98226118
Best Epoch:0 with PSNR: 32.3327
       1	1.00000000e-03	1.30164237e-03	6.93698408e-04	1.08102965e-01	32.33457050	0.90688416	4.95797682
Best Epoch:1 with PSNR: 32.3346
       2	1.00000000e-03	1.29787024e-03	6.93409686e-04	1.12094754e-01	32.33710337	0.90689378	4.92854786
Best Epoch:2 with PSNR: 32.3371
       3	1.00000000e-03	1.29878766e-03	6.93080929e-04	1.20022975e-01	32.34008167	0.90690350	4.89598989
Best Epoch:3 with PSNR: 32.3401
       4	1.00000000e-03	1.29687709e-03	6.92795223e-04	1.32085851e-01	32.34273187	0.90691292	4.86381960
Best Epoch:4 with PSNR: 32.3427
       5	1.00000000e-03	1.29750008e-03	6.92650070e-04	1.43890174e-01	32.34422472	0.90691825	4.83615971
Best Epoch:5 with PSNR: 32.3442
       6	1.00000000e-03	1.29366706e-03	6.92604453e-04	1.51113148e-01	32.34481462	0.90691727	4.81648111
Best Epoch:6 with PSNR: 32.3448
       7	1.00000000e-03	1.28848663e-03	6.92593324e-04	1.52867523e-01	32.34502292	0.90691096	4.80373526
Best Epoch:7 with PSNR: 32.3450
       8	1.00000000e-03	1.29614355e-03	6.92597014e-04	1.53429781e-01	32.34511190	0.90690414	4.79066372
Best Epoch:8 with PSNR: 32.3451
       9	1.00000000e-03	1.29737897e-03	6.92603528e-04	1.53451543e-01	32.34517809	0.90689726	4.77742910
Best Epoch:9 with PSNR: 32.3452
      10	1.00000000e-03	1.29519300e-03	6.92613772e-04	1.53003804e-01	32.34523378	0.90689058	4.76278543
Best Epoch:10 with PSNR: 32.3452
      11	1.00000000e-03	1.29344209e-03	6.92638289e-04	1.51892321e-01	32.34518342	0.90688547	4.74565268
      12	1.00000000e-03	1.29683702e-03	6.92653930e-04	1.52217552e-01	32.34523428	0.90688030	4.72574186
Best Epoch:12 with PSNR: 32.3452
      13	1.00000000e-03	1.29292064e-03	6.92681549e-04	1.51958223e-01	32.34519174	0.90687599	4.70483446
      14	1.00000000e-03	1.29667647e-03	6.92720199e-04	1.49597697e-01	32.34499778	0.90686899	4.68304205
      15	1.00000000e-03	1.29147037e-03	6.92742132e-04	1.49946360e-01	32.34501979	0.90686159	4.65797853
      16	1.00000000e-03	1.29768026e-03	6.92760345e-04	1.50033450e-01	32.34505555	0.90685407	4.63154554
      17	1.00000000e-03	1.29745544e-03	6.92793570e-04	1.49457087e-01	32.34493658	0.90684701	4.60409927
      18	1.00000000e-03	1.29447205e-03	6.92844245e-04	1.47045733e-01	32.34469326	0.90683397	4.57392550
      19	1.00000000e-03	1.29628776e-03	6.92876108e-04	1.47383370e-01	32.34466022	0.90682537	4.54268646
      20	1.00000000e-03	1.29112960e-03	6.92936289e-04	1.47638294e-01	32.34447051	0.90681711	4.51040125
      21	1.00000000e-03	1.29714453e-03	6.92988245e-04	1.44710456e-01	32.34416681	0.90680578	4.47745848
      22	1.00000000e-03	1.29140723e-03	6.93040568e-04	1.45940071e-01	32.34408624	0.90679521	4.44282532
      23	1.00000000e-03	1.29100175e-03	6.93130266e-04	1.42659493e-01	32.34361122	0.90678483	4.40882063
      24	1.00000000e-03	1.28977037e-03	6.93179056e-04	1.45953666e-01	32.34367993	0.90677479	4.37272358
      25	1.00000000e-03	1.28589755e-03	6.93288201e-04	1.44623521e-01	32.34325294	0.90676012	4.33721876
      26	1.00000000e-03	1.29086765e-03	6.93340780e-04	1.43290111e-01	32.34297577	0.90675567	4.30228090
      27	1.00000000e-03	1.29252659e-03	6.93398854e-04	1.42891721e-01	32.34274084	0.90674834	4.26515722
      28	1.00000000e-03	1.29512122e-03	6.93556812e-04	1.38506681e-01	32.34178496	0.90673384	4.22963762
      29	1.00000000e-03	1.28802639e-03	6.93621958e-04	1.40598100e-01	32.34176540	0.90672470	4.19311333
      30	1.00000000e-03	1.29009147e-03	6.93693443e-04	1.37411003e-01	32.34125087	0.90671819	4.15708923
      31	1.00000000e-03	1.29437836e-03	6.93835015e-04	1.39496921e-01	32.34084274	0.90670139	4.12107897
      32	1.00000000e-03	1.29485946e-03	6.93866680e-04	1.39574525e-01	32.34074424	0.90670304	4.08468485
      33	1.00000000e-03	1.29668988e-03	6.93956448e-04	1.35338104e-01	32.34005828	0.90669719	4.04969168
      34	1.00000000e-03	1.29886090e-03	6.94009836e-04	1.39830428e-01	32.34013522	0.90668369	4.01454353
      35	1.00000000e-03	1.28831217e-03	6.94165734e-04	1.38809070e-01	32.33953380	0.90667145	3.98022461
      36	1.00000000e-03	1.29698826e-03	6.94301788e-04	1.38593566e-01	32.33900505	0.90666173	3.94584990
      37	1.00000000e-03	1.29328659e-03	6.94410130e-04	1.36839131e-01	32.33836988	0.90665066	3.91204476
      38	1.00000000e-03	1.28919035e-03	6.94467145e-04	1.35497883e-01	32.33807442	0.90664921	3.87833214
      39	1.00000000e-03	1.29642264e-03	6.94565487e-04	1.35301435e-01	32.33765418	0.90663982	3.84700346
      40	1.00000000e-03	1.29545105e-03	6.94664923e-04	1.33874519e-01	32.33711305	0.90662831	3.81151056
